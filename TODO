Things needed to be done/answered
========================

[DONE] ) Repeat Tests on Code rather than comments

[DONE] ) Map feature vectors back to file somehow so that predictions file and results are more meaningful

1) [DONE] BUG!! : why does adding new testing data change the predicted values? tfidf values are differnt for tests
* right now trying to figure out why the test and the train idfs are differnt for the same strings 
* transductive SVM where some of the training labels can be zero and the SVM will classsify them. 
** Should the tfidfs be cacl'd against the train, test or both data sets **

Transductive SVM : http://www.cs.cornell.edu/People/tj/publications/joachims_99c.pdf
-Supposed to be great for text classification. Small training large test-set.

2) [wed] Rgs basecase Example

4) [DONE] To try, +feature selection +@parmas
	- split variables based on camel case? i.e. rushiGanmukhi to the features rushi and ganmukhi
	- further clean up words
	- word stemming?

5) [wat] Overall system?, how to know what is correct/incorrect?
	- how to know and learn what is correct incorrect?
		-> Relevance Feedback, user marks set of original documents returned by the query, this is used as the train data
	- how to link up with java system? [dont worrry about this yet.]
	- what data from the plugin to use? Using Surrounding Code?
	- what is the corpus? The downloaded API? Web docs?
	- how are the results going to be tested/compared


