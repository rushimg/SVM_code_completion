  public void match(Vector<AceToken> tokens) throws MatchException {
    int start = -1;
    int end = -1;

    for (int i = 0; i < tokens.size(); i++) {
      //
      // we found the starting token
      //
      if (tokens.get(i).getByteOffset().start() == mByteOffset.start()) {
        start = i;
      }

      //
      // we do not tokenize dashed-words, hence the start may be inside a token
      // e.g. Saddam => pro-Saddam
      // the same situation will happen due to (uncommon) annotation errors
      //
      else if (mByteOffset.start() > tokens.get(i).getByteOffset().start()
          && mByteOffset.start() < tokens.get(i).getByteOffset().end()) {
        start = i;
      }

      //
      // we found the ending token
      // Note: ACE is inclusive for the end position, my tokenization is not
      // in ACE: end position == position of last byte in token
      // in .sgm.pre: end position == position of last byte + 1
      //
      if (tokens.get(i).getByteOffset().end() == mByteOffset.end() + 1) {
        end = i;
        break;
      }

      //
      // we do not tokenize dashed-words, hence the end may be inside a token
      // e.g. Conference => Conference-leading
      // the same situation will happen due to (uncommon) annotation errors
      //
      else if (mByteOffset.end() >= tokens.get(i).getByteOffset().start()
          && mByteOffset.end() < tokens.get(i).getByteOffset().end() - 1) {
        end = i;
        break;
      }
    }

    if (start >= 0 && end >= 0) {
      mTokenOffset = new Span(start, end);
      // mPhrase = makePhrase(tokens, mTokenOffset);
    } else {
      throw new MatchException("Match failed!");
    }
  }

  @Override
  public String toString() {
    return "AceCharSeq [mByteOffset=" + mByteOffset + ", mText=" + mText
        + ", mTokenOffset=" + mTokenOffset + "]";
  }

