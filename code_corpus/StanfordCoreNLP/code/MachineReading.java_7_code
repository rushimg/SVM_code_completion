  public List<String> run() throws Exception {
    this.forceRetraining= !MachineReadingProperties.loadModel;
  	
    if (MachineReadingProperties.trainOnly) {
      this.forceRetraining= true;
    }
    List<String> retMsg = new ArrayList<String>();
    boolean haveSerializedEntityExtractor = serializedModelExists(MachineReadingProperties.serializedEntityExtractorPath);
    boolean haveSerializedRelationExtractor = serializedModelExists(MachineReadingProperties.serializedRelationExtractorPath);
    boolean haveSerializedEventExtractor = serializedModelExists(MachineReadingProperties.serializedEventExtractorPath);
    Annotation training = null;
    Annotation aux = null;
    if ((MachineReadingProperties.extractEntities && !haveSerializedEntityExtractor) || 
        (MachineReadingProperties.extractRelations && !haveSerializedRelationExtractor) || 
        (MachineReadingProperties.extractEvents && !haveSerializedEventExtractor) ||
        this.forceRetraining|| MachineReadingProperties.crossValidate){
      // load training sentences
      training = loadOrMakeSerializedSentences(MachineReadingProperties.trainPath, reader, new File(MachineReadingProperties.serializedTrainingSentencesPath));
			if (auxReader != null) {
			  MachineReadingProperties.logger.severe("Reading auxiliary dataset from " + MachineReadingProperties.auxDataPath + "...");
				aux = loadOrMakeSerializedSentences(MachineReadingProperties.auxDataPath, auxReader, new File(
				    MachineReadingProperties.serializedAuxTrainingSentencesPath));
				MachineReadingProperties.logger.severe("Done reading auxiliary dataset.");
			}
    }
    
    Annotation testing = null;
    if (!MachineReadingProperties.trainOnly && !MachineReadingProperties.crossValidate) {
      // load test sentences
      File serializedTestSentences = new File(MachineReadingProperties.serializedTestSentencesPath);
      testing = loadOrMakeSerializedSentences(MachineReadingProperties.testPath, reader, serializedTestSentences);
    }
      
    //
    // create the actual datasets to be used for training and annotation
    //
    makeDataSets(training, testing, aux);
    
    //
    // process (training + annotate) one partition at a time
    //
    for(int partition = 0; partition < datasets.length; partition ++){
      assert(datasets.length > partition);
      assert(datasets[partition] != null);
      assert(MachineReadingProperties.trainOnly || datasets[partition].second() != null);
      
      // train all models
      train(datasets[partition].first(), (MachineReadingProperties.crossValidate ? partition : -1));
      // annotate using all models
      if(! MachineReadingProperties.trainOnly){
        MachineReadingProperties.logger.info("annotating partition " + partition );
        annotate(datasets[partition].second(), (MachineReadingProperties.crossValidate ? partition: -1));
      }
    }
    
    //
    // now report overall results 
    //
    if(! MachineReadingProperties.trainOnly){
      // merge test sets for the gold data
      Annotation gold = new Annotation("");
      for(int i = 0; i < datasets.length; i ++) AnnotationUtils.addSentences(gold, datasets[i].second().get(CoreAnnotations.SentencesAnnotation.class));
      
      // merge test sets with predicted annotations
      Annotation[] mergedPredictions = new Annotation[3];
      assert(predictions != null);
      for (int taskLevel = 0; taskLevel < mergedPredictions.length; taskLevel++) {
        mergedPredictions[taskLevel] = new Annotation("");
        for(int fold = 0; fold < predictions[taskLevel].length; fold ++){
          if (predictions[taskLevel][fold] == null) continue;
          AnnotationUtils.addSentences(mergedPredictions[taskLevel], predictions[taskLevel][fold].get(CoreAnnotations.SentencesAnnotation.class));
        }
      }
      //
      // evaluate all tasks: entity, relation, and event recognition
      //
      if(MachineReadingProperties.extractEntities && ! entityResultsPrinterSet.isEmpty()){
      	retMsg.addAll(printTask("entity extraction", entityResultsPrinterSet, gold, mergedPredictions[ENTITY_LEVEL]));
      }
      
      if(MachineReadingProperties.extractRelations && ! getRelationResultsPrinterSet().isEmpty()){
      	retMsg.addAll(printTask("relation extraction", getRelationResultsPrinterSet(), gold, mergedPredictions[RELATION_LEVEL]));
      }
      
      //
      // Save the sentences with the predicted annotations
      //
      if (MachineReadingProperties.extractEntities && MachineReadingProperties.serializedEntityExtractionResults != null) 
        IOUtils.writeObjectToFile(mergedPredictions[ENTITY_LEVEL], MachineReadingProperties.serializedEntityExtractionResults);
      if (MachineReadingProperties.extractRelations && MachineReadingProperties.serializedRelationExtractionResults != null) 
        IOUtils.writeObjectToFile(mergedPredictions[RELATION_LEVEL],MachineReadingProperties.serializedRelationExtractionResults);
      if (MachineReadingProperties.extractEvents && MachineReadingProperties.serializedEventExtractionResults != null)
        IOUtils.writeObjectToFile(mergedPredictions[EVENT_LEVEL],MachineReadingProperties.serializedEventExtractionResults);
      
    }
     
    return retMsg;
  }
  
  protected List<String> printTask(String taskName, Set<ResultsPrinter> printers, Annotation gold, Annotation pred) {
    List<String> retMsg = new ArrayList<String>();
    for (ResultsPrinter rp : printers){
      String msg = rp.printResults(gold, pred);
      retMsg.add(msg);
      MachineReadingProperties.logger.severe("Overall " + taskName + " results, using printer " + rp.getClass() + ":\n" + msg);
    }
    return retMsg;
  }
  
  protected void train(Annotation training, int partition) throws Exception {
    //
    // train entity extraction
    //
    if (MachineReadingProperties.extractEntities) {
      MachineReadingProperties.logger.info("Training entity extraction model(s)");
      if (partition != -1) MachineReadingProperties.logger.info("In partition #" + partition);
      String modelName = MachineReadingProperties.serializedEntityExtractorPath;
      if (partition != -1) modelName += "." + partition;
      File modelFile = new File(modelName);
      
      MachineReadingProperties.logger.fine("forceRetraining = " + this.forceRetraining+ ", modelFile.exists = " + modelFile.exists());
      if(! this.forceRetraining&& modelFile.exists()){
        MachineReadingProperties.logger.info("Loading entity extraction model from " + modelName + " ...");
        entityExtractor = BasicEntityExtractor.load(modelName, MachineReadingProperties.entityClassifier, false);
      } else {
        MachineReadingProperties.logger.info("Training entity extraction model...");
        entityExtractor = makeEntityExtractor(MachineReadingProperties.entityClassifier, MachineReadingProperties.entityGazetteerPath);
        entityExtractor.train(training);
        MachineReadingProperties.logger.info("Serializing entity extraction model to " + modelName + " ...");
        entityExtractor.save(modelName);
      }
    }
    
    //
    // train relation extraction
    //
    if (MachineReadingProperties.extractRelations) {
      MachineReadingProperties.logger.info("Training relation extraction model(s)");
      if (partition != -1)
        MachineReadingProperties.logger.info("In partition #" + partition);
      String modelName = MachineReadingProperties.serializedRelationExtractorPath;
      if (partition != -1)
        modelName += "." + partition;
      Annotation predicted = null;
      
      if (MachineReadingProperties.useRelationExtractionModelMerging) {
        String[] modelNames = MachineReadingProperties.serializedRelationExtractorPath.split(",");
        if (partition != -1) {
          for (int i = 0; i < modelNames.length; i++) {
            modelNames[i] += "." + partition;
          }
        }
        
        relationExtractor = ExtractorMerger.buildRelationExtractorMerger(modelNames);
      } else if (!this.forceRetraining&& new File(modelName).exists()) {
        MachineReadingProperties.logger.info("Loading relation extraction model from " + modelName + " ...");
        relationExtractor = BasicRelationExtractor.load(modelName);
      } else {
        RelationFeatureFactory rff = makeRelationFeatureFactory(MachineReadingProperties.relationFeatureFactoryClass, MachineReadingProperties.relationFeatures, MachineReadingProperties.doNotLexicalizeFirstArg);
        
        if (MachineReadingProperties.trainRelationsUsingPredictedEntities) {
      		// generate predicted entities
      		assert(entityExtractor != null);
          predicted = AnnotationUtils.deepMentionCopy(training);
          entityExtractor.annotate(predicted);
          for (ResultsPrinter rp : entityResultsPrinterSet){
            String msg = rp.printResults(training, predicted);
            MachineReadingProperties.logger.info("Training relation extraction using predicted entitities: entity scores using printer " + rp.getClass() + ":\n" + msg);
          }
          
          // change relation mentions to use predicted entity mentions rather than gold ones
          try {
          	changeGoldRelationArgsToPredicted(predicted);
          } catch (Exception e) {
          	// we may get here for unknown EntityMentionComparator class
          	throw new RuntimeException(e);
          }
      	}

      	Annotation dataset;
        if (MachineReadingProperties.trainRelationsUsingPredictedEntities) {
          dataset = predicted;
        } else {
          dataset = training;
        }
      	
        Set<String> relationsToSkip = new HashSet<String>(StringUtils.split(MachineReadingProperties.relationsToSkipDuringTraining, ","));
        List<List<RelationMention>> backedUpRelations = new ArrayList<List<RelationMention>>();
      	if (relationsToSkip.size() > 0) {
      	  // we need to backup the relations since removeSkippableRelations modifies dataset in place and we can't duplicate CoreMaps safely (or can we?)
          for (CoreMap sent : dataset.get(CoreAnnotations.SentencesAnnotation.class)) {
            List<RelationMention> relationMentions = sent.get(MachineReadingAnnotations.RelationMentionsAnnotation.class);
            backedUpRelations.add(relationMentions);
          }
      	  
      	  removeSkippableRelations(dataset, relationsToSkip);
      	}
      	
      	relationExtractor = new BasicRelationExtractor(rff, MachineReadingProperties.createUnrelatedRelations, makeRelationMentionFactory(MachineReadingProperties.relationMentionFactoryClass));
        Execution.fillOptions(relationExtractor, args);
      	//Arguments.parse(args,relationExtractor);
        MachineReadingProperties.logger.info("Training relation extraction model...");
        relationExtractor.train(dataset);
        MachineReadingProperties.logger.info("Serializing relation extraction model to " + modelName + " ...");
        relationExtractor.save(modelName);

        if (relationsToSkip.size() > 0) {
          // restore backed up relations into dataset
          int sentenceIndex = 0;
          
          for (CoreMap sentence : dataset.get(CoreAnnotations.SentencesAnnotation.class)) {
            List<RelationMention> relationMentions = backedUpRelations.get(sentenceIndex);
            sentence.set(MachineReadingAnnotations.RelationMentionsAnnotation.class, relationMentions);
            sentenceIndex++;
          }
        }
      }
    }

    //
    // train event extraction -- currently just works with MSTBasedEventExtractor
    //
    if (MachineReadingProperties.extractEvents) {
      MachineReadingProperties.logger.info("Training event extraction model(s)");
      if (partition != -1) MachineReadingProperties.logger.info("In partition #" + partition);
      String modelName = MachineReadingProperties.serializedEventExtractorPath;
      if (partition != -1) modelName += "." + partition;
      File modelFile = new File(modelName);

      Annotation predicted = null;
      if(!this.forceRetraining&& modelFile.exists()) {
        MachineReadingProperties.logger.info("Loading event extraction model from " + modelName + " ...");
        Method mstLoader = (Class.forName("MSTBasedEventExtractor")).getMethod("load", String.class);
        eventExtractor = (Extractor) mstLoader.invoke(null, modelName);
      } else {
        if (MachineReadingProperties.trainEventsUsingPredictedEntities) {
          // generate predicted entities
          assert(entityExtractor != null);
          predicted = AnnotationUtils.deepMentionCopy(training);
          entityExtractor.annotate(predicted);
          for (ResultsPrinter rp : entityResultsPrinterSet){
            String msg = rp.printResults(training, predicted);
            MachineReadingProperties.logger.info("Training event extraction using predicted entitities: entity scores using printer " + rp.getClass() + ":\n" + msg);
          }
          
          // TODO: need an equivalent of changeGoldRelationArgsToPredicted here?
        }

        Constructor<?> mstConstructor = (Class.forName("edu.stanford.nlp.ie.machinereading.MSTBasedEventExtractor")).getConstructor(boolean.class);
        eventExtractor = (Extractor) mstConstructor.newInstance(MachineReadingProperties.trainEventsUsingPredictedEntities);

        MachineReadingProperties.logger.info("Training event extraction model...");
        if (MachineReadingProperties.trainRelationsUsingPredictedEntities) {
          eventExtractor.train(predicted);
        } else {
          eventExtractor.train(training);
        }
        MachineReadingProperties.logger.info("Serializing event extraction model to " + modelName + " ...");
        eventExtractor.save(modelName);
      }
    }
  }

