    def should_retry(self, response, chunked_transfer=False):
        provider = self.bucket.connection.provider
        if not chunked_transfer:
            if response.status in [500, 503]:
                # 500 & 503 can be plain retries.
                return True
            if response.getheader('location'):
                # If there's a redirect, plain retry.
                return True
        if 200 <= response.status <= 299:
            self.etag = response.getheader('etag')
            if self.etag != '"%s"' % self.md5:
                raise provider.storage_data_error(
                    'ETag from S3 did not match computed MD5')
            return True
        if response.status == 400:
            # The 400 must be trapped so the retry handler can check to
            # see if it was a timeout.
            # If ``RequestTimeout`` is present, we'll retry. Otherwise, bomb
            # out.
            body = response.read()
            err = provider.storage_response_error(
                response.status,
                response.reason,
                body
            )
            if err.error_code in ['RequestTimeout']:
                raise PleaseRetryException(
                    "Saw %s, retrying" % err.error_code,
                    response=response
                )
        return False
