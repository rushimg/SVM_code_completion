File to store which files correspond to which tests
---------------------------------------------------------------------------------
NOTE: all tests below are run using tfidf of words in the comments as the features

0)~30 train(~5 correct) / 10 manual test 100%/100% used entire code from #4 as training and created 10 test examples out of snippets from these comments

1) 5 train(1 correct) / 5 test(1 correct)	80% Accuracy[everything as -1]

2) 20 train(1 correct) / 20 test(1 correct)	95% Accuracy[everything as -1] same data as first test just padded with erroneous files

3) 20 train(10 correct) / 20 test(10 correct)	PR(53%)	general and random[everything classified one way except for one], files from one class correct,not from that class incorrect 

4) 10 train(3 correct) / 10 test (3 correct)	PR(100%/100%) specific all files within same class, correct methods are all constructors

5) 12 train(3 correct)/ 12 test(3 correct)	PR(100%/100%) same as above but with added noise of out of class constructors

6) 18k train(20 correct) / 18k test(20 correct)	PR(71.43%/68.18%)[13 incorrectly classified]	see if one class can be picked out in entire corpus

7) 40 train/test (20 correct)	PR(100%/95.45%)

8) 10 train/test (1 corrrect) Accuracy 90%(everything classified same way) postive train and test examples were the same

9) Same as 8 with different files

10) 47 train/test each (12 correct) PR(100%/33.33%) Distinguish JSONObject files from ther JSON files
 
18) 									comparison between two APIS
* Larger scales ~100-1000 examples

** Feature selection

** Remove one and try and replace

*** Twitter-api test, above are on aws

*** Incorporate @param, type tags in features somehow

****other: mix apis (3-4) see if can decifer if belongs in twitter, aws etc..

