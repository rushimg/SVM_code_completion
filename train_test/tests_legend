File to store which files correspond to which tests
---------------------------------------------------------------------------------
NOTE: all tests below are run using tfidf of words in the comments as the features

* 0) run on code text, run with freq rather than tfidf

1) 5 train(1 correct) / 5 test(1 correct)	80% Accuracy[everything as -1]

2) 20 train(1 correct) / 20 test(1 correct)	95% Accuracy[everything as -1] same data as first test just padded with erroneous files

3) 20 train(10 correct) / 20 test(10 correct)	PR(53%)	general and random[everything classified one way except for one], files from one class correct,not from that class incorrect 

4) 10 train(3 correct) / 10 test (3 correct)	PR(100%/100%) specific all files within same class, correct methods are all constructors

5) 12 train(3 correct)/ 12 test(3 correct)	PR(100%/100%) same as above but with added noise of out of class constructors

6) 18k train(20 correct) / 18k test(20 correct)	PR(71.43%/68.18%)[13 incorrectly classified]	see if one class can be picked out in entire corpus

7) 20 train(10 correct) / 20 test(10 correct) general

* 8) 20 train(10 correct) / 20 test(10 correct) specific all files within same class

** 9) 100 train(50% CORRECT) / 100 test(50% CORECT)

** 10) 1000 train / 1000 test 	

** 11) 1000 train / 200 test

** 12) Remove one and try and replace 100 train, 100 test

*** 13) Twitter-api test, above are on aws

*** 14) Incorporate @param, type tags in features somehow

**** 15) other: mix apis (3-4) see if can decifer if belongs in twitter, aws etc..

